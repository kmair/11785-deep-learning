{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzVHVHCVdYSD"
   },
   "source": [
    "# Predicting speech tags \n",
    "\n",
    "Refer: `Frame Level Classification of Speech.doc` for the problem description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why it's a bad idea to just pad the phonemes?\n",
    "\n",
    "Ther range of data varies from 50 frames to about a 1000 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wILkk5uNBlI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m-QyGa5P-aQU"
   },
   "outputs": [],
   "source": [
    "# Path to home\n",
    "PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2563,
     "status": "ok",
     "timestamp": 1571245788675,
     "user": {
      "displayName": "Kanishk Mair",
      "photoUrl": "",
      "userId": "10858185497480457260"
     },
     "user_tz": 240
    },
    "id": "hqh27OgnruMz",
    "outputId": "b2a603f3-e9e3-4aed-dba8-9ae180e4f5cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Check the work space is enabled  with GPU.\n",
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(PATH, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load(os.path.join(data_folder, 'train.npy'), allow_pickle=True)\n",
    "train_labels = np.load(os.path.join(data_folder, 'train_labels.npy'), allow_pickle=True)\n",
    "\n",
    "dev = np.load(os.path.join(data_folder, 'dev.npy'), allow_pickle=True)\n",
    "dev_labels = np.load(os.path.join(data_folder, 'dev_labels.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 97968,
     "status": "ok",
     "timestamp": 1571245934051,
     "user": {
      "displayName": "Kanishk Mair",
      "photoUrl": "",
      "userId": "10858185497480457260"
     },
     "user_tz": 240
    },
    "id": "kpLctmADgRTY",
    "outputId": "487e72bd-ed8c-4392-bdab-8650a5f87385"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24500,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SxL-A66gX9o"
   },
   "outputs": [],
   "source": [
    "# # Using subset of complete data when modifying\n",
    "\n",
    "# dev = dev[:20]\n",
    "# dev_labels = dev_labels[:20]\n",
    "# train = train[:10]\n",
    "# train_labels = train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pnBp3-DuPZhY"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        assert len(x) == len(y)\n",
    "        self._x = x\n",
    "        self._y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._x)\n",
    "      \n",
    "    def __getitem__(self, index):\n",
    "        x_item = self._x[index]\n",
    "        return torch.FloatTensor(x_item), torch.FloatTensor(self._y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0Dt1ficNvHa"
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train, train_labels)\n",
    "\n",
    "load_train = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = 1,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "dev_dataset = TensorDataset(dev, dev_labels)\n",
    "\n",
    "load_valid = DataLoader(\n",
    "    dev_dataset,\n",
    "    batch_size = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sp-GXCSn2IaI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56873,
     "status": "ok",
     "timestamp": 1571245934063,
     "user": {
      "displayName": "Kanishk Mair",
      "photoUrl": "",
      "userId": "10858185497480457260"
     },
     "user_tz": 240
    },
    "id": "RjOHGH1P2K84",
    "outputId": "afe88487-981b-4cdd-baf3-e37ccf150df2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LaZLTGssv0bL"
   },
   "source": [
    "## Notes:\n",
    "3 layer: Plateaus at 2-2.4 loss\n",
    "5 layer: starts over-fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below hyperparameters were recommended values.\n",
    "Layers were determined by hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7166,
     "status": "ok",
     "timestamp": 1571246135554,
     "user": {
      "displayName": "Kanishk Mair",
      "photoUrl": "",
      "userId": "10858185497480457260"
     },
     "user_tz": 240
    },
    "id": "mPh7B8uOy6uM",
    "outputId": "600cb91b-1003-4c2a-f9df-e468ecd64394"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.2261, 0.0635, 0.4993, 0.8936, 0.1026, 0.4744, 0.9558, 0.9520,\n",
       "           0.9811, 0.8996]],\n",
       " \n",
       "         [[0.6332, 0.8928, 0.3691, 0.7337, 0.3118, 0.7843, 0.3708, 0.8421,\n",
       "           0.6584, 0.3892]],\n",
       " \n",
       "         [[0.1393, 0.9138, 0.9894, 0.3627, 0.1949, 0.1461, 0.8501, 0.8128,\n",
       "           0.1747, 0.1738]],\n",
       " \n",
       "         [[0.6443, 0.4553, 0.3866, 0.0910, 0.4398, 0.9565, 0.2513, 0.8180,\n",
       "           0.1458, 0.6562]],\n",
       " \n",
       "         [[0.4320, 0.3839, 0.3742, 0.1623, 0.1179, 0.5242, 0.2380, 0.8052,\n",
       "           0.2964, 0.8655]],\n",
       " \n",
       "         [[0.9025, 0.7097, 0.8623, 0.2287, 0.2640, 0.7032, 0.6808, 0.3681,\n",
       "           0.8246, 0.3216]],\n",
       " \n",
       "         [[0.2206, 0.1264, 0.4175, 0.6466, 0.4449, 0.1084, 0.9714, 0.8738,\n",
       "           0.7677, 0.4911]],\n",
       " \n",
       "         [[0.4271, 0.3124, 0.3283, 0.8620, 0.8813, 0.5015, 0.6065, 0.1876,\n",
       "           0.8247, 0.9766]]]),\n",
       " tensor([[[0.2657, 0.9852, 0.5736, 0.5801, 0.6973, 0.6188, 0.4101, 0.1752,\n",
       "           0.9324, 0.9191]],\n",
       " \n",
       "         [[0.1456, 0.2634, 0.4260, 0.6772, 0.1259, 0.6433, 0.0328, 0.4842,\n",
       "           0.0040, 0.9328]],\n",
       " \n",
       "         [[0.7795, 0.6710, 0.4996, 0.8481, 0.8582, 0.8914, 0.8880, 0.5368,\n",
       "           0.9883, 0.1779]],\n",
       " \n",
       "         [[0.0710, 0.9550, 0.0447, 0.1229, 0.7798, 0.7168, 0.6221, 0.5693,\n",
       "           0.1269, 0.6457]],\n",
       " \n",
       "         [[0.0146, 0.2272, 0.8769, 0.0586, 0.8083, 0.8937, 0.4510, 0.5331,\n",
       "           0.0046, 0.2289]],\n",
       " \n",
       "         [[0.5324, 0.1224, 0.7808, 0.1222, 0.7258, 0.3564, 0.7810, 0.7211,\n",
       "           0.3997, 0.9190]],\n",
       " \n",
       "         [[0.2770, 0.9728, 0.9232, 0.9387, 0.7513, 0.9537, 0.0017, 0.7402,\n",
       "           0.4240, 0.0871]],\n",
       " \n",
       "         [[0.8962, 0.7945, 0.2412, 0.4063, 0.9502, 0.4085, 0.4712, 0.3037,\n",
       "           0.4210, 0.9733]]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 40\n",
    "hidden_dim = 10\n",
    "vocab_size = 138 # [0-137]\n",
    "layers=4\n",
    "\n",
    "def hidden_init():\n",
    "    return (torch.rand(layers*2, 1, hidden_dim).to(DEVICE) ,\n",
    "            torch.rand(layers*2, 1, hidden_dim).to(DEVICE))\n",
    "\n",
    "hidden_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GOUw8_7SwdTz"
   },
   "outputs": [],
   "source": [
    "class LSTM_model(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(LSTM_model, self).__init__()\n",
    "        self.vocab_size = 138 #vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim, num_layers=layers, dropout = 0.2, bidirectional = True).to(DEVICE)\n",
    "        self.linear = torch.nn.Linear(hidden_dim*2, vocab_size)       # *2 applied if bidir = true\n",
    "        self.softmax = torch.nn.functional.softmax\n",
    "        \n",
    "    def forward(self, encrypted):\n",
    "        lstm_in = encrypted.transpose(0,1)\n",
    "\n",
    "        lstm_out, lstm_hidden = self.lstm(lstm_in.float(), hidden_init())\n",
    "        \n",
    "        scores = self.linear(lstm_out)\n",
    "        scores = scores.transpose(1, 2)\n",
    "\n",
    "        return scores\n",
    "\n",
    "model = LSTM_model(vocab_size, embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "710wAAeIzIqw"
   },
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2277,
     "status": "ok",
     "timestamp": 1571113802846,
     "user": {
      "displayName": "Kanishk Mair",
      "photoUrl": "",
      "userId": "10858185497480457260"
     },
     "user_tz": 240
    },
    "id": "wyqHMD_hrP6e",
    "outputId": "f5a20c72-5d95-4d9a-8f98-0858e4a3b481"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(PATH + 'model_5.sav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJ9KYuMJIJmq"
   },
   "outputs": [],
   "source": [
    "# Printing validation loss at regular intervals\n",
    "validation_time = len(train) / 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zprCdaUN_hHZ"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "class LSTM_Trainer():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.001) \n",
    "\n",
    "    def get_loss(self, encrypted, original) :\n",
    "        encrypted = encrypted.to(DEVICE).long()\n",
    "        original = original.to(DEVICE).long()\n",
    "\n",
    "        scores = self.model.forward(encrypted)\n",
    "        original = original.transpose(0,1)\n",
    "        original = original.long()\n",
    "\n",
    "        loss = self.loss_fn(scores, original)  # <- Training loss\n",
    "        return loss\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        accuracies, max_accuracy = [], 0\n",
    "        best_valid_loss = 10   # V.high initialization\n",
    "\n",
    "        with open(os.path.join(PATH, 'history.csv'),'w') as writer:\n",
    "            for N in range(num_epochs):\n",
    "                print('Epoch: {}'.format(N))\n",
    "                for i, (encrypted, original) in enumerate(load_train):  #dataset(num_examples):\n",
    "                    self.optimizer.zero_grad()\n",
    "  \n",
    "                    loss = self.get_loss(encrypted, original)  # <- Training loss\n",
    "                    loss.backward()\n",
    "\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                # Validation\n",
    "                    if i % validation_time == 0:\n",
    "\n",
    "                        print('Validation:' + str(i))\n",
    "                        validation_loss = []\n",
    "                        for (val_encrypted, val_original) in load_valid:    #val dataset(num_examples):\n",
    "                            val_loss = self.get_loss(val_encrypted, val_original) \n",
    "                      \n",
    "                            validation_loss.append(val_loss.item())\n",
    "\n",
    "                        avg_loss = sum(validation_loss) / len(validation_loss)\n",
    "                        print('Training Loss: {:6.4f}'.format(loss.item()))\n",
    "                        print('Validation Loss: {:6.4f}'.format(avg_loss))        \n",
    "                        writer.write(str(N)+','+str(i)+','+str(loss.item())+','+str(avg_loss))\n",
    "                        writer.write('\\n')\n",
    "\n",
    "                # Saving the model after an epoch\n",
    "                model_saved = os.path.join(PATH, 'model_' + str(N+1) + '.sav')\n",
    "                torch.save(self.model.state_dict(), model_saved)\n",
    "\n",
    "                print('Train Loss at end of epoch: {:6.4f}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2gQ6UyAyA9n8"
   },
   "outputs": [],
   "source": [
    "trainer = LSTM_Trainer(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m3jrzQuDA6u2"
   },
   "source": [
    "Working on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23844432,
     "status": "ok",
     "timestamp": 1571185600741,
     "user": {
      "displayName": "Kanishk Mair",
      "photoUrl": "",
      "userId": "10858185497480457260"
     },
     "user_tz": 240
    },
    "id": "GqhfDYHBA9dt",
    "outputId": "e46d542c-56e8-42c7-8864-84839951cbdb"
   },
   "outputs": [],
   "source": [
    "# Below call starts training models for required epochs\n",
    "\n",
    "trainer.train(n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above module will train the output `model` using which the below predictions on test will be carried out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        assert len(x) == len(y)\n",
    "        self._x = x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._x)\n",
    "      \n",
    "    def __getitem__(self, index):\n",
    "        x_item = self._x[index]\n",
    "        return torch.FloatTensor(x_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load(os.path.join(data_folder, 'test.npy'), allow_pickle=True)\n",
    "\n",
    "test_dataset = TestDataset(test)\n",
    "\n",
    "load_test = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = 1,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 23626,
     "status": "error",
     "timestamp": 1571246190844,
     "user": {
      "displayName": "Kanishk Mair",
      "photoUrl": "",
      "userId": "10858185497480457260"
     },
     "user_tz": 240
    },
    "id": "MXWszLX3uzmo",
    "outputId": "5804226a-cb52-4966-db0c-f36db4f9e253"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5f99dacf6249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mencrypted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mload_valid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mencrypted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencrypted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencrypted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-8a91799dbd33>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encrypted)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#     lstm_in = lstm_in.to(DEVICE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#     if lstm_hidden[0].is_cuda:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 526\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "soft = torch.nn.Softmax(dim=0)\n",
    "\n",
    "with open('hw1_submission.csv') as output:\n",
    "    output.write('id,label')\n",
    "    output_id = 0\n",
    "    for encrypted in load_test:\n",
    "        encrypted = encrypted.to(DEVICE)\n",
    "        scores = model.forward(encrypted)\n",
    "\n",
    "        soft_scores = soft(scores[0])      \n",
    "        predictions = torch.max(soft_scores, 0)   \n",
    "        for prediction in predictions:\n",
    "            output.write(output_id + ',' + prediction)\n",
    "            output_id += 1\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Colab_101.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
